# ğŸ˜ Bambara BPE Tokenizer

> A clean, research-grade **Byte Pair Encoding (BPE)** tokenizer built from scratch for the **Bambara** language.  
> Designed for linguists, NLP researchers, and developers working on Mande language processing.  
> Fully Linux-friendly and ready to run locally or in Google Colab.

---

## ğŸ§© Overview

The **Bambara BPE Tokenizer** is a lightweight implementation of the Byte Pair Encoding algorithm.  
It allows you to:
- Train subword tokenization models on Bambara text
- Handle Bambara diacritics (`É›`, `É”`, `Å‹`, `É²`)
- Encode and decode text into consistent subword units
- Use it as a standalone module or integrate into a larger NLP pipeline

---

## ğŸ§  Conceptual Illustration

Below is a simple visual explanation of how the tokenizer works:

<p align="center">
  <img src="docs/bpe_diagram.PNG" alt="Bambara BPE Tokenizer Diagram" width="450"/>
</p>

> Example:  
> `"Bamanankan"` â†’ `"Ba"` `"ma"` `"nan"` `"kan"`

This shows how the tokenizer learns to break a Bambara word into subword components â€”  
a key step for efficient NLP modeling on low-resource languages.

---

## ğŸ“ Project Structure

bambara-bpe-tokenizer/
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ requirements.txt # Dependencies list
â”œâ”€â”€ LICENSE # MIT License
â”œâ”€â”€ data/ # Example corpus files
â”‚ â””â”€â”€ sample_corpus.txt
â”œâ”€â”€ bambara_bpe_tokenizer/ # Core Python package
â”‚ â”œâ”€â”€ init.py
â”‚ â””â”€â”€ tokenizer.py
â”œâ”€â”€ examples/ # Demos and notebooks
â”‚ â””â”€â”€ demo_colab.ipynb
â”œâ”€â”€ docs/ # Documentation & diagrams
â”‚ â””â”€â”€ bpe_diagram.png
â””â”€â”€ tests/ # Unit tests
â””â”€â”€ test_tokenizer.py

---

## âš™ï¸ Installation (Linux / macOS)

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com//bambara-bpe-tokenizer.git
cd bambara-bpe-tokenizer
2ï¸âƒ£ (Optional) Create and activate a virtual environment
bash
Copy code
python3 -m venv .venv
source .venv/bin/activate
3ï¸âƒ£ Install dependencies
bash
Copy code
pip install -r requirements.txt
4ï¸âƒ£ Install the package
bash
Copy code
pip install -e .
ğŸš€ Quick Start (Python)
python
Copy code
from bambara_bpe_tokenizer.tokenizer import BambaraBPETokenizer

# Example Bambara corpus
corpus = [
    "A bÉ› taa",
    "Nâ€™a fÉ› ka kÉ› nyÉ›",
    "A bÉ› se ka taa"
]

# Train tokenizer
bpe = BambaraBPETokenizer()
bpe.learn_bpe(corpus, num_merges=100)

# Encode & decode
text = "A bÉ› taa"
encoded = bpe.encode(text)
decoded = bpe.decode(encoded)

print("Encoded:", encoded)
print("Decoded:", decoded)
Output:

bash
Copy code
Encoded: ['A', 'bÉ›', 'taa']
Decoded: A bÉ› taa
ğŸ§° Command-Line Usage
You can also train and use the tokenizer directly from your Linux terminal:

bash
Copy code
# Train tokenizer on a corpus file
python3 -m bambara_bpe_tokenizer.tokenizer --train data/sample_corpus.txt --merges 1000

# Encode a sentence
python3 -m bambara_bpe_tokenizer.tokenizer --encode "A bÉ› taa"

# Decode tokens
python3 -m bambara_bpe_tokenizer.tokenizer --decode "A@@ bÉ›@@ taa"
â˜ï¸ Run in Google Colab
You can try the interactive demo directly on Google Colab:


ğŸ§ª Testing
Run unit tests using pytest:

bash
Copy code
pytest -v
ğŸ” Example Corpus
A small sample corpus is provided under data/sample_corpus.txt.
You can replace it with your own Bambara text file to train a larger tokenizer model.

text
Copy code
A bÉ› taa
Nâ€™a fÉ› ka kÉ› nyÉ›
A bÉ› se ka taa
ğŸ§­ Roadmap
Feature	Status
Core BPE training and encoding	âœ…
CLI support for Linux	âœ…
Colab demo	âœ…
SentencePiece wrapper	ğŸ”œ
Pretrained merges for Bambara Wikipedia	ğŸ”œ
Hugging Face integration	ğŸ”œ

ğŸ¤ Contributing
Contributions are welcome!
Please fork the repository and submit a pull request with clear commit messages:

bash
Copy code
git checkout -b feature/add-new-rule
git commit -m "Add new merge rule optimization"
git push origin feature/add-new-rule
ğŸ“œ License
This project is licensed under the MIT License â€” free to use and modify for research and educational purposes.

ğŸ‘¨ğŸ¾â€ğŸ’» Author
Sambou Kone
ğŸ“§ samboukone99@gmail.com
ğŸŒ Bamako, Mali

â€œLanguage is data â€” and data deserves respect.â€ ğŸ‡²ğŸ‡±
